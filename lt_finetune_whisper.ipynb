{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monoramasn/Speech_fairness/blob/main/lt_finetune_whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xFAsz4sF32V",
        "outputId": "58dae425-45eb-4b2d-a2a0-d20ae52886c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.26.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.6.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install -U accelerate\n",
        "! pip install -U transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w9gX3E6kFZV",
        "outputId": "49702f72-7363-4a7a-b196-7b72034b30c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20231117)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "SjuSgSTeG1bn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import argparse\n",
        "import evaluate\n",
        "from dataclasses import dataclass\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from typing import Any, Dict, List, Union\n",
        "from datasets import DatasetDict, Audio, load_from_disk, concatenate_datasets\n",
        "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
        "from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lt_voxpopuli_dataset = load_dataset(\"facebook/voxpopuli\", \"lt\", split=['train', 'test'])"
      ],
      "metadata": {
        "id": "-_nZiPT2RVF8"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = lt_voxpopuli_dataset[0].remove_columns(['audio_id', 'language', 'raw_text', 'gender', 'speaker_id', 'is_gold_transcript', 'accent'])\n"
      ],
      "metadata": {
        "id": "PZHuEGfiRjlv"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = lt_voxpopuli_dataset[1].remove_columns(['audio_id', 'language', 'raw_text', 'gender', 'speaker_id', 'is_gold_transcript', 'accent'])\n"
      ],
      "metadata": {
        "id": "6AgsHX6tRycN"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "p59B5ZsIGw8_"
      },
      "outputs": [],
      "source": [
        "#rom datasets import load_dataset, load_metric\n",
        "#voxpopuli_dataset = load_dataset(\"facebook/voxpopuli\", \"lt\", split=['train', 'test'])\n",
        "#voxpopuli_dataset = load_dataset(\"facebook/voxpopuli\", \"et\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fh94uywoG7Ao"
      },
      "outputs": [],
      "source": [
        "#dataset_lt = voxpopuli_dataset.remove_columns(['audio_id', 'language', 'raw_text', 'gender', 'speaker_id', 'is_gold_transcript', 'accent'])\n",
        "#dataset_lt = voxpopuli_dataset[0].remove_columns(['audio_id', 'language', 'raw_text', 'speaker_id', 'is_gold_transcript', 'accent'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "gzaJdMai3ibH"
      },
      "outputs": [],
      "source": [
        "gradient_checkpointing = True\n",
        "freeze_feature_encoder = False\n",
        "freeze_encoder = False\n",
        "\n",
        "do_normalize_eval = True\n",
        "do_lower_case = False\n",
        "do_remove_punctuation = False\n",
        "normalizer = BasicTextNormalizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "DWG1V9kyG-x4"
      },
      "outputs": [],
      "source": [
        "model_checkpoint= \"openai/whisper-large\"\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_checkpoint)\n",
        "tokenizer = WhisperTokenizer.from_pretrained(model_checkpoint, language=\"Lithuanian\", task=\"transcribe\")\n",
        "processor = WhisperProcessor.from_pretrained(model_checkpoint, language=\"Lithuanian\", task=\"transcribe\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(model_checkpoint)\n",
        "\n",
        "if model.config.decoder_start_token_id is None:\n",
        "    raise ValueError(\"Make sure that `config.decoder_start_token_id` is correctly defined\")\n",
        "\n",
        "if freeze_feature_encoder:\n",
        "    model.freeze_feature_encoder()\n",
        "\n",
        "if freeze_encoder:\n",
        "    model.freeze_encoder()\n",
        "    model.model.encoder.gradient_checkpointing = False\n",
        "\n",
        "\n",
        "model.config.forced_decoder_ids = None\n",
        "model.config.suppress_tokens = []\n",
        "\n",
        "if gradient_checkpointing:\n",
        "    model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "88NkCEsUHE-P"
      },
      "outputs": [],
      "source": [
        "model_checkpoint_name = model_checkpoint.split(\"/\")[-1]\n",
        "repo_name = f\"{model_checkpoint_name}-demo-colab\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "6EdLoKcWOsaV"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(batch):\n",
        "    # Load and resample audio data to the expected sampling rate\n",
        "    audio = batch[\"audio\"]\n",
        "    input_features = processor.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "    #input_features = input_features.reshape(-1, 80, 3000)\n",
        "\n",
        "    # Ensure the last dimension of input_features is 3000\n",
        "    if input_features.shape[-1] < 3000:\n",
        "        padding = torch.zeros(3000 - input_features.shape[-1])\n",
        "        input_features = torch.cat([input_features, padding], dim=0)\n",
        "\n",
        "    batch[\"input_features\"] = input_features\n",
        "\n",
        "    # Compute input length of audio sample in seconds\n",
        "    batch[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n",
        "\n",
        "    # Optional pre-processing steps\n",
        "    transcription = batch[\"normalized_text\"]\n",
        "    if do_lower_case:\n",
        "        transcription = transcription.lower()\n",
        "    if do_remove_punctuation:\n",
        "        transcription = normalizer(transcription).strip()\n",
        "\n",
        "    # Encode target text to label ids\n",
        "    batch[\"labels\"] = processor.tokenizer(transcription, padding=\"max_length\", max_length=max_label_length).input_ids\n",
        "\n",
        "    return batch\n",
        "\n",
        "max_label_length = model.config.max_length\n",
        "min_input_length = 0.0\n",
        "max_input_length = 30.0\n",
        "def is_in_length_range(length, labels):\n",
        "    return min_input_length < length < max_input_length and 0 < len(labels) < max_label_length"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(prepare_dataset, batch_size=8)\n",
        "#test_dataset = test_dataset.map(prepare_dataset, batch_size=8)\n"
      ],
      "metadata": {
        "id": "P20_TAfdWlvR"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset = train_dataset.map(prepare_dataset, batch_size=8)\n",
        "test_dataset = test_dataset.map(prepare_dataset, batch_size=8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "40a4c7e0f4844659a9dece459ef2668f",
            "f723ed72f0a944e49741861cef823bd3",
            "90e9e11290eb442ca95391755d1b03d5",
            "f225dc62e10647138466bd186b98db26",
            "83c6861516e04f03947613108d42b66f",
            "cd4b91eca2c24d4b86973226bf1bf9f8",
            "748f6326aaa54ff486cc585f09f0fa8a",
            "6fda1654cba3448196fb72848f559d62",
            "8c969eba537e4a4e83216500cde26e0f",
            "fe0a5e6585d9495aa1046968924489c8",
            "f533ef35107342df9ced7a336f222803"
          ]
        },
        "id": "eL9XPtPPXk51",
        "outputId": "9a7617c9-a841-4ad7-f6c2-77f2d96c3331"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/42 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40a4c7e0f4844659a9dece459ef2668f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHAEZMjC-YrF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Apply preprocessing and ensure 'labels' key is added\n",
        "#dataset_lt1 = dataset_lt.map(prepare_dataset, batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIkSlx3WBWpO"
      },
      "outputs": [],
      "source": [
        "#y=dataset_it1[\"train\"][\"input_features\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "UFmN8W8oB8Zh",
        "outputId": "3ab4e577-a794-4381-aba5-153bf735d8c1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d42a218f02ff>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ],
      "source": [
        "#import numpy as np\n",
        "#y=np.array(y)\n",
        "#y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "eIC5wvij3yIO"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
        "        # first treat the audio inputs by simply returning torch tensors\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # get the tokenized label sequences\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        # pad the labels to max length\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # if bos token is appended in previous tokenization step,\n",
        "        # cut bos token here as it's append later anyways\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqpGN4utO_28",
        "outputId": "9490f310-a31c-4161-bf60-ca293f810e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET PREPARATION COMPLETED\n"
          ]
        }
      ],
      "source": [
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
        "print('DATASET PREPARATION COMPLETED')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29BXtOb232Ov",
        "outputId": "4f812baf-966e-4e32-d80f-358a9fc49181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for wer contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/wer/wer.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "wer_metric = load_metric(\"wer\")\n",
        "def compute_metrics(pred):\n",
        "    pred_logits = pred.predictions\n",
        "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
        "\n",
        "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "\n",
        "    pred_str = processor.batch_decode(pred_ids)\n",
        "    # we do not want to group tokens when computing the metrics\n",
        "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
        "\n",
        "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"wer\": wer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTAq1U2K35ey",
        "outputId": "74bca762-b354-4176-b654-82d762fce758"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WhisperForConditionalGeneration(\n",
              "  (model): WhisperModel(\n",
              "    (encoder): WhisperEncoder(\n",
              "      (conv1): Conv1d(80, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
              "      (embed_positions): Embedding(1500, 1280)\n",
              "      (layers): ModuleList(\n",
              "        (0-31): 32 x WhisperEncoderLayer(\n",
              "          (self_attn): WhisperAttention(\n",
              "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): WhisperDecoder(\n",
              "      (embed_tokens): Embedding(51865, 1280, padding_idx=50257)\n",
              "      (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
              "      (layers): ModuleList(\n",
              "        (0-31): 32 x WhisperDecoderLayer(\n",
              "          (self_attn): WhisperAttention(\n",
              "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): WhisperAttention(\n",
              "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (proj_out): Linear(in_features=1280, out_features=51865, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "j32PHlW1dnmZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Attention mechanism\n",
        "class WhisperAttention(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.k_proj = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.v_proj = nn.Linear(d_model, d_model, bias=True)\n",
        "        self.q_proj = nn.Linear(d_model, d_model, bias=True)\n",
        "        self.out_proj = nn.Linear(d_model, d_model, bias=True)\n",
        "\n",
        "    def forward(self, k, v, q):\n",
        "        k = self.k_proj(k)\n",
        "        v = self.v_proj(v)\n",
        "        q = self.q_proj(q)\n",
        "\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / torch.sqrt(torch.tensor(k.size(-1), dtype=torch.float32))\n",
        "        attn_probs = F.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        context = torch.matmul(attn_probs, v)\n",
        "        return self.out_proj(context)\n",
        "\n",
        "# Encoder layer\n",
        "class WhisperEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super().__init__()\n",
        "        self.self_attn = WhisperAttention(d_model)\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.activation_fn = nn.GELU()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.final_layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_output = self.self_attn(x, x, x)\n",
        "        x = self.self_attn_layer_norm(x + attn_output)\n",
        "\n",
        "        fc_output = self.fc2(self.activation_fn(self.fc1(x)))\n",
        "        x = self.final_layer_norm(x + fc_output)\n",
        "        return x\n",
        "\n",
        "# Encoder\n",
        "class WhisperEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, n_layers, d_ff, max_len):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(input_dim, d_model, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv1d(d_model, d_model, kernel_size=3, stride=2, padding=1)\n",
        "        self.embed_positions = nn.Embedding(max_len, d_model)\n",
        "        self.layers = nn.ModuleList([WhisperEncoderLayer(d_model, d_ff) for _ in range(n_layers)])\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "\n",
        "        # Transpose to match the (batch_size, seq_len, features) format\n",
        "        x = x.transpose(1, 2)  # now shape: (batch_size, seq_len, d_model)\n",
        "\n",
        "        # Adjusting the position_ids based on the actual sequence length after convolution\n",
        "        position_ids = torch.arange(x.size(1), dtype=torch.long, device=x.device)\n",
        "        position_embeddings = self.embed_positions(position_ids)  # now shape: (seq_len, d_model)\n",
        "\n",
        "        x += position_embeddings\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        x = self.layer_norm(x)\n",
        "        return x\n",
        "\n",
        "# Decoder layer\n",
        "class WhisperDecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super().__init__()\n",
        "        self.self_attn = WhisperAttention(d_model)\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.encoder_attn = WhisperAttention(d_model)\n",
        "        self.encoder_attn_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.activation_fn = nn.GELU()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.final_layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "        self_attn_output = self.self_attn(x, x, x)\n",
        "        x = self.self_attn_layer_norm(x + self_attn_output)\n",
        "\n",
        "        enc_attn_output = self.encoder_attn(encoder_output, encoder_output, x)\n",
        "        x = self.encoder_attn_layer_norm(x + enc_attn_output)\n",
        "\n",
        "        fc_output = self.fc2(self.activation_fn(self.fc1(x)))\n",
        "        x = self.final_layer_norm(x + fc_output)\n",
        "        return x\n",
        "# Decoder\n",
        "class WhisperDecoder(nn.Module):\n",
        "    def __init__(self, d_model, n_layers, d_ff, max_len, vocab_size):\n",
        "        super().__init__()\n",
        "        self.embed_tokens = nn.Embedding(vocab_size, d_model, padding_idx=50257)\n",
        "        self.embed_positions = nn.Embedding(max_len, d_model)\n",
        "        self.layers = nn.ModuleList([WhisperDecoderLayer(d_model, d_ff) for _ in range(n_layers)])\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, encoder_output):\n",
        "        position_ids = torch.arange(x.size(1), dtype=torch.long, device=x.device)\n",
        "        x = self.embed_tokens(x) + self.embed_positions(position_ids)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output)\n",
        "\n",
        "        x = self.layer_norm(x)\n",
        "        return x\n",
        "\n",
        "# Complete model\n",
        "class WhisperForfinetune(nn.Module):\n",
        "    def __init__(self, input_dim=80, encoder_d_model=512, encoder_n_layers=6, encoder_d_ff=2048, max_len=1500, vocab_size=51865):\n",
        "        super().__init__()\n",
        "        self.encoder = WhisperEncoder(input_dim, encoder_d_model, encoder_n_layers, encoder_d_ff, max_len)\n",
        "        self.decoder = WhisperDecoder(encoder_d_model, encoder_n_layers, encoder_d_ff, max_len, vocab_size)\n",
        "        self.proj_out = nn.Linear(encoder_d_model, vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, input_features, labels):\n",
        "        encoder_output = self.encoder(input_features)\n",
        "        decoder_output = self.decoder(labels, encoder_output)\n",
        "        logits = self.proj_out(decoder_output)\n",
        "\n",
        "        outputs = {'logits': logits}\n",
        "        if labels is not None:\n",
        "          loss_fn = nn.CrossEntropyLoss()\n",
        "          # Reshape labels and logits to compute loss, adjust dimensions as necessary\n",
        "          loss = loss_fn(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
        "          outputs['loss'] = loss\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Instantiate the model\n",
        "model1 = WhisperForfinetune()\n",
        "\n",
        "# Example input (dummy data)\n",
        "#input_features = torch.randn(1, 80, 3000)  # Batch size x Input dimension x Sequence length\n",
        "#labels = torch.randint(0, 51865, (1, 100))  # Example target token sequence\n",
        "\n",
        "# Forward pass\n",
        "#output = model1(input_features, labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "TDTwjCzAnF-E",
        "outputId": "bcc4e295-cc33-4590-ad5c-35e1c43bd8e5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'output' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-61bdaec43c72>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#output.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
          ]
        }
      ],
      "source": [
        "#output.shape\n",
        "#output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "4BszQVtk2-Uv"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "  output_dir=repo_name,\n",
        "  group_by_length=True,\n",
        "  per_device_train_batch_size=8,\n",
        "  evaluation_strategy=\"steps\",\n",
        "  num_train_epochs=50,\n",
        "  fp16=True,\n",
        "  gradient_checkpointing=False,\n",
        "  save_steps=50,\n",
        "  eval_steps=50,\n",
        "  logging_steps=50,\n",
        "  learning_rate=1e-4,\n",
        "  weight_decay=0.005,\n",
        "  warmup_steps=1000,\n",
        "  save_total_limit=2,\n",
        "  push_to_hub=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "pZ9-dwuT3Ctf"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model1,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=processor.feature_extractor,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O19GDanw3KGv",
        "outputId": "e0a8934a-5ddb-45f8-db7a-4986f45d4f26"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='451' max='2850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 451/2850 13:34 < 1:12:34, 0.55 it/s, Epoch 7.89/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Wer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>8.758900</td>\n",
              "      <td>4.100206</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.310200</td>\n",
              "      <td>1.937528</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.871600</td>\n",
              "      <td>1.718981</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.498200</td>\n",
              "      <td>1.223534</td>\n",
              "      <td>0.993902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.065200</td>\n",
              "      <td>0.896815</td>\n",
              "      <td>0.987805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.747200</td>\n",
              "      <td>0.630608</td>\n",
              "      <td>0.939024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.522400</td>\n",
              "      <td>0.471797</td>\n",
              "      <td>0.841463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.401500</td>\n",
              "      <td>0.356278</td>\n",
              "      <td>0.746341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.302100</td>\n",
              "      <td>0.284400</td>\n",
              "      <td>0.634146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2850' max='2850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2850/2850 1:32:32, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Wer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>8.758900</td>\n",
              "      <td>4.100206</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.310200</td>\n",
              "      <td>1.937528</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.871600</td>\n",
              "      <td>1.718981</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.498200</td>\n",
              "      <td>1.223534</td>\n",
              "      <td>0.993902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.065200</td>\n",
              "      <td>0.896815</td>\n",
              "      <td>0.987805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.747200</td>\n",
              "      <td>0.630608</td>\n",
              "      <td>0.939024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.522400</td>\n",
              "      <td>0.471797</td>\n",
              "      <td>0.841463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.401500</td>\n",
              "      <td>0.356278</td>\n",
              "      <td>0.746341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.302100</td>\n",
              "      <td>0.284400</td>\n",
              "      <td>0.634146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.232500</td>\n",
              "      <td>0.228063</td>\n",
              "      <td>0.568293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.190800</td>\n",
              "      <td>0.188717</td>\n",
              "      <td>0.497561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.147000</td>\n",
              "      <td>0.158432</td>\n",
              "      <td>0.367073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.117600</td>\n",
              "      <td>0.135190</td>\n",
              "      <td>0.304878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.119636</td>\n",
              "      <td>0.282927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.083800</td>\n",
              "      <td>0.101552</td>\n",
              "      <td>0.230488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.065900</td>\n",
              "      <td>0.089002</td>\n",
              "      <td>0.196341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.053900</td>\n",
              "      <td>0.079061</td>\n",
              "      <td>0.190244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.046000</td>\n",
              "      <td>0.071065</td>\n",
              "      <td>0.157317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.037200</td>\n",
              "      <td>0.063944</td>\n",
              "      <td>0.136585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.061326</td>\n",
              "      <td>0.136585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.025000</td>\n",
              "      <td>0.054959</td>\n",
              "      <td>0.126829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.021800</td>\n",
              "      <td>0.051198</td>\n",
              "      <td>0.108537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.017800</td>\n",
              "      <td>0.048694</td>\n",
              "      <td>0.097561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.014500</td>\n",
              "      <td>0.046967</td>\n",
              "      <td>0.095122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.012800</td>\n",
              "      <td>0.045199</td>\n",
              "      <td>0.095122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.010600</td>\n",
              "      <td>0.043301</td>\n",
              "      <td>0.091463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.009300</td>\n",
              "      <td>0.042388</td>\n",
              "      <td>0.090244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.007800</td>\n",
              "      <td>0.041542</td>\n",
              "      <td>0.090244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.006800</td>\n",
              "      <td>0.040190</td>\n",
              "      <td>0.089024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.006400</td>\n",
              "      <td>0.040290</td>\n",
              "      <td>0.091463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.005500</td>\n",
              "      <td>0.039090</td>\n",
              "      <td>0.089024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.004700</td>\n",
              "      <td>0.038606</td>\n",
              "      <td>0.090244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.004200</td>\n",
              "      <td>0.038153</td>\n",
              "      <td>0.089024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>0.037699</td>\n",
              "      <td>0.090244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.036889</td>\n",
              "      <td>0.091463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.042426</td>\n",
              "      <td>0.107317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.005400</td>\n",
              "      <td>0.036126</td>\n",
              "      <td>0.082927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>0.035538</td>\n",
              "      <td>0.086585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.002900</td>\n",
              "      <td>0.035150</td>\n",
              "      <td>0.087805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>0.034897</td>\n",
              "      <td>0.087805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.034623</td>\n",
              "      <td>0.086585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>0.034484</td>\n",
              "      <td>0.087805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>0.034296</td>\n",
              "      <td>0.087805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>0.034211</td>\n",
              "      <td>0.087805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.034125</td>\n",
              "      <td>0.087805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.034014</td>\n",
              "      <td>0.089024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.001900</td>\n",
              "      <td>0.033929</td>\n",
              "      <td>0.087805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>0.033848</td>\n",
              "      <td>0.087805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>0.033793</td>\n",
              "      <td>0.089024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>0.033744</td>\n",
              "      <td>0.089024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>0.033729</td>\n",
              "      <td>0.089024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>0.033650</td>\n",
              "      <td>0.089024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>0.033621</td>\n",
              "      <td>0.087805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>0.033615</td>\n",
              "      <td>0.089024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>0.033575</td>\n",
              "      <td>0.089024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>0.033576</td>\n",
              "      <td>0.089024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>0.033566</td>\n",
              "      <td>0.089024</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2850, training_loss=0.32966564981299534, metrics={'train_runtime': 5557.0109, 'train_samples_per_second': 4.103, 'train_steps_per_second': 0.513, 'total_flos': 0.0, 'train_loss': 0.32966564981299534, 'epoch': 50.0})"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "QvPM6cFv3NRH",
        "outputId": "79a00f08-a0f5-48d6-97fb-9f2ea81057eb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6/6 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.03356553986668587,\n",
              " 'eval_wer': 0.08902439024390243,\n",
              " 'eval_runtime': 36.5342,\n",
              " 'eval_samples_per_second': 1.15,\n",
              " 'eval_steps_per_second': 0.164,\n",
              " 'epoch': 50.0}"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyPBIbpfOcF2iTgrxODWVnr4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "40a4c7e0f4844659a9dece459ef2668f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f723ed72f0a944e49741861cef823bd3",
              "IPY_MODEL_90e9e11290eb442ca95391755d1b03d5",
              "IPY_MODEL_f225dc62e10647138466bd186b98db26"
            ],
            "layout": "IPY_MODEL_83c6861516e04f03947613108d42b66f"
          }
        },
        "f723ed72f0a944e49741861cef823bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd4b91eca2c24d4b86973226bf1bf9f8",
            "placeholder": "",
            "style": "IPY_MODEL_748f6326aaa54ff486cc585f09f0fa8a",
            "value": "Map: 100%"
          }
        },
        "90e9e11290eb442ca95391755d1b03d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fda1654cba3448196fb72848f559d62",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c969eba537e4a4e83216500cde26e0f",
            "value": 42
          }
        },
        "f225dc62e10647138466bd186b98db26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe0a5e6585d9495aa1046968924489c8",
            "placeholder": "",
            "style": "IPY_MODEL_f533ef35107342df9ced7a336f222803",
            "value": " 42/42 [00:08&lt;00:00, 83.12 examples/s]"
          }
        },
        "83c6861516e04f03947613108d42b66f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd4b91eca2c24d4b86973226bf1bf9f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "748f6326aaa54ff486cc585f09f0fa8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fda1654cba3448196fb72848f559d62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c969eba537e4a4e83216500cde26e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe0a5e6585d9495aa1046968924489c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f533ef35107342df9ced7a336f222803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}