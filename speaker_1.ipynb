{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a0f19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890daa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "#import torchaudio\n",
    "import sys,os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "# models\n",
    "from sklearn import linear_model, naive_bayes, neighbors\n",
    "#from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "#from keras.optimizers import Adam\n",
    "#from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcd6adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Libraries for the evaluation\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "950444ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(columns=['speaker_id1', 'gender'])\n",
    "\n",
    "f = open(\"E:/Libri/LibriSpeech/SPEAKERS.txt\", \"r\", encoding=\"UTF8\").readlines()\n",
    "i = 0\n",
    "for idx, line in enumerate(f):\n",
    "    if idx > 11:\n",
    "        parsed = re.split('\\s+',line)\n",
    "        if parsed[4] == 'train-clean-100':\n",
    "            labels.loc[i] = parsed[0], parsed[2] # speaker_id and label (M/F)\n",
    "            i += 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "444a96a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"E:/Libri/LibriSpeech/train-clean-100/\"\n",
    "df = pd.DataFrame(columns=['gender'])                 \n",
    "file_path = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "# loading the features in the first dataframe\n",
    "for path, subdirs, files in os.walk(root):\n",
    "    for name in files:\n",
    "        gender = path.split('/')[4]\n",
    "        if name.endswith(\".flac\"):\n",
    "            file_path.append(path + '/' + name)\n",
    "            df.loc[i] = [gender]\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "025629b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:/Libri/LibriSpeech/train-clean-100/103/103-1...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:/Libri/LibriSpeech/train-clean-100/103/103-1...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:/Libri/LibriSpeech/train-clean-100/103/103-1...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:/Libri/LibriSpeech/train-clean-100/103/103-1...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:/Libri/LibriSpeech/train-clean-100/103/103-1...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28533</th>\n",
       "      <td>E:/Libri/LibriSpeech/train-clean-100/911/911-1...</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28534</th>\n",
       "      <td>E:/Libri/LibriSpeech/train-clean-100/911/911-1...</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28535</th>\n",
       "      <td>E:/Libri/LibriSpeech/train-clean-100/911/911-1...</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28536</th>\n",
       "      <td>E:/Libri/LibriSpeech/train-clean-100/911/911-1...</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28537</th>\n",
       "      <td>E:/Libri/LibriSpeech/train-clean-100/911/911-1...</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28538 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path gender\n",
       "0      E:/Libri/LibriSpeech/train-clean-100/103/103-1...    103\n",
       "1      E:/Libri/LibriSpeech/train-clean-100/103/103-1...    103\n",
       "2      E:/Libri/LibriSpeech/train-clean-100/103/103-1...    103\n",
       "3      E:/Libri/LibriSpeech/train-clean-100/103/103-1...    103\n",
       "4      E:/Libri/LibriSpeech/train-clean-100/103/103-1...    103\n",
       "...                                                  ...    ...\n",
       "28533  E:/Libri/LibriSpeech/train-clean-100/911/911-1...    911\n",
       "28534  E:/Libri/LibriSpeech/train-clean-100/911/911-1...    911\n",
       "28535  E:/Libri/LibriSpeech/train-clean-100/911/911-1...    911\n",
       "28536  E:/Libri/LibriSpeech/train-clean-100/911/911-1...    911\n",
       "28537  E:/Libri/LibriSpeech/train-clean-100/911/911-1...    911\n",
       "\n",
       "[28538 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([pd.DataFrame(file_path, columns = ['path']),df],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33525a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('E:/Libri/speaker_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d55d07b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler as sd\n",
    "from sklearn.model_selection import train_test_split\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7262a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>Speaker_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-379.455688</td>\n",
       "      <td>97.028137</td>\n",
       "      <td>-36.862133</td>\n",
       "      <td>58.326141</td>\n",
       "      <td>-14.381740</td>\n",
       "      <td>18.083685</td>\n",
       "      <td>-13.535484</td>\n",
       "      <td>-1.980425</td>\n",
       "      <td>6.867363</td>\n",
       "      <td>-1.436182</td>\n",
       "      <td>...</td>\n",
       "      <td>6.590969</td>\n",
       "      <td>4.147519</td>\n",
       "      <td>2.915069</td>\n",
       "      <td>2.506089</td>\n",
       "      <td>2.704373</td>\n",
       "      <td>0.896116</td>\n",
       "      <td>0.402769</td>\n",
       "      <td>-2.776433</td>\n",
       "      <td>-0.392300</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-350.678436</td>\n",
       "      <td>104.953583</td>\n",
       "      <td>-50.797516</td>\n",
       "      <td>63.575645</td>\n",
       "      <td>-20.301023</td>\n",
       "      <td>16.125052</td>\n",
       "      <td>-18.338022</td>\n",
       "      <td>-4.701718</td>\n",
       "      <td>5.564232</td>\n",
       "      <td>-3.718176</td>\n",
       "      <td>...</td>\n",
       "      <td>5.044738</td>\n",
       "      <td>4.084303</td>\n",
       "      <td>2.290769</td>\n",
       "      <td>1.581125</td>\n",
       "      <td>2.657886</td>\n",
       "      <td>1.554843</td>\n",
       "      <td>2.869262</td>\n",
       "      <td>-0.345722</td>\n",
       "      <td>1.761455</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-338.924103</td>\n",
       "      <td>103.865723</td>\n",
       "      <td>-51.616165</td>\n",
       "      <td>55.547260</td>\n",
       "      <td>-14.175528</td>\n",
       "      <td>12.698159</td>\n",
       "      <td>-15.529408</td>\n",
       "      <td>-6.788486</td>\n",
       "      <td>6.311726</td>\n",
       "      <td>-1.932351</td>\n",
       "      <td>...</td>\n",
       "      <td>5.090059</td>\n",
       "      <td>3.858420</td>\n",
       "      <td>1.970551</td>\n",
       "      <td>1.166767</td>\n",
       "      <td>4.533372</td>\n",
       "      <td>2.390000</td>\n",
       "      <td>2.891569</td>\n",
       "      <td>-0.540090</td>\n",
       "      <td>-0.186476</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-346.993133</td>\n",
       "      <td>103.250298</td>\n",
       "      <td>-46.157928</td>\n",
       "      <td>55.580742</td>\n",
       "      <td>-14.027334</td>\n",
       "      <td>6.038419</td>\n",
       "      <td>-17.537346</td>\n",
       "      <td>-1.607846</td>\n",
       "      <td>10.737667</td>\n",
       "      <td>-4.196127</td>\n",
       "      <td>...</td>\n",
       "      <td>3.346047</td>\n",
       "      <td>2.461340</td>\n",
       "      <td>2.484034</td>\n",
       "      <td>3.027887</td>\n",
       "      <td>4.524765</td>\n",
       "      <td>2.431338</td>\n",
       "      <td>2.143259</td>\n",
       "      <td>-1.152794</td>\n",
       "      <td>-0.398699</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-350.193420</td>\n",
       "      <td>107.248901</td>\n",
       "      <td>-42.734859</td>\n",
       "      <td>57.279823</td>\n",
       "      <td>-20.294600</td>\n",
       "      <td>7.000971</td>\n",
       "      <td>-20.205288</td>\n",
       "      <td>0.712615</td>\n",
       "      <td>8.332971</td>\n",
       "      <td>-5.744866</td>\n",
       "      <td>...</td>\n",
       "      <td>4.356198</td>\n",
       "      <td>5.268185</td>\n",
       "      <td>3.117359</td>\n",
       "      <td>2.990666</td>\n",
       "      <td>4.309646</td>\n",
       "      <td>1.087925</td>\n",
       "      <td>3.075779</td>\n",
       "      <td>-1.321528</td>\n",
       "      <td>-0.485248</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1          2          3          4          5  \\\n",
       "0 -379.455688   97.028137 -36.862133  58.326141 -14.381740  18.083685   \n",
       "1 -350.678436  104.953583 -50.797516  63.575645 -20.301023  16.125052   \n",
       "2 -338.924103  103.865723 -51.616165  55.547260 -14.175528  12.698159   \n",
       "3 -346.993133  103.250298 -46.157928  55.580742 -14.027334   6.038419   \n",
       "4 -350.193420  107.248901 -42.734859  57.279823 -20.294600   7.000971   \n",
       "\n",
       "           6         7          8         9  ...        31        32  \\\n",
       "0 -13.535484 -1.980425   6.867363 -1.436182  ...  6.590969  4.147519   \n",
       "1 -18.338022 -4.701718   5.564232 -3.718176  ...  5.044738  4.084303   \n",
       "2 -15.529408 -6.788486   6.311726 -1.932351  ...  5.090059  3.858420   \n",
       "3 -17.537346 -1.607846  10.737667 -4.196127  ...  3.346047  2.461340   \n",
       "4 -20.205288  0.712615   8.332971 -5.744866  ...  4.356198  5.268185   \n",
       "\n",
       "         33        34        35        36        37        38        39  \\\n",
       "0  2.915069  2.506089  2.704373  0.896116  0.402769 -2.776433 -0.392300   \n",
       "1  2.290769  1.581125  2.657886  1.554843  2.869262 -0.345722  1.761455   \n",
       "2  1.970551  1.166767  4.533372  2.390000  2.891569 -0.540090 -0.186476   \n",
       "3  2.484034  3.027887  4.524765  2.431338  2.143259 -1.152794 -0.398699   \n",
       "4  3.117359  2.990666  4.309646  1.087925  3.075779 -1.321528 -0.485248   \n",
       "\n",
       "   Speaker_ID  \n",
       "0         103  \n",
       "1         103  \n",
       "2         103  \n",
       "3         103  \n",
       "4         103  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('E:/Libri/mfcc_train_speaker.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e576c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.speaker_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9410d536",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, 0:-1]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37b32182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>Speaker_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-379.455688</td>\n",
       "      <td>97.028137</td>\n",
       "      <td>-36.862133</td>\n",
       "      <td>58.326141</td>\n",
       "      <td>-14.381740</td>\n",
       "      <td>18.083685</td>\n",
       "      <td>-13.535484</td>\n",
       "      <td>-1.980425</td>\n",
       "      <td>6.867363</td>\n",
       "      <td>-1.436182</td>\n",
       "      <td>...</td>\n",
       "      <td>6.590969</td>\n",
       "      <td>4.147519</td>\n",
       "      <td>2.915069</td>\n",
       "      <td>2.506089</td>\n",
       "      <td>2.704373</td>\n",
       "      <td>0.896116</td>\n",
       "      <td>0.402769</td>\n",
       "      <td>-2.776433</td>\n",
       "      <td>-0.392300</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-350.678436</td>\n",
       "      <td>104.953583</td>\n",
       "      <td>-50.797516</td>\n",
       "      <td>63.575645</td>\n",
       "      <td>-20.301023</td>\n",
       "      <td>16.125052</td>\n",
       "      <td>-18.338022</td>\n",
       "      <td>-4.701718</td>\n",
       "      <td>5.564232</td>\n",
       "      <td>-3.718176</td>\n",
       "      <td>...</td>\n",
       "      <td>5.044738</td>\n",
       "      <td>4.084303</td>\n",
       "      <td>2.290769</td>\n",
       "      <td>1.581125</td>\n",
       "      <td>2.657886</td>\n",
       "      <td>1.554843</td>\n",
       "      <td>2.869262</td>\n",
       "      <td>-0.345722</td>\n",
       "      <td>1.761455</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-338.924103</td>\n",
       "      <td>103.865723</td>\n",
       "      <td>-51.616165</td>\n",
       "      <td>55.547260</td>\n",
       "      <td>-14.175528</td>\n",
       "      <td>12.698159</td>\n",
       "      <td>-15.529408</td>\n",
       "      <td>-6.788486</td>\n",
       "      <td>6.311726</td>\n",
       "      <td>-1.932351</td>\n",
       "      <td>...</td>\n",
       "      <td>5.090059</td>\n",
       "      <td>3.858420</td>\n",
       "      <td>1.970551</td>\n",
       "      <td>1.166767</td>\n",
       "      <td>4.533372</td>\n",
       "      <td>2.390000</td>\n",
       "      <td>2.891569</td>\n",
       "      <td>-0.540090</td>\n",
       "      <td>-0.186476</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-346.993133</td>\n",
       "      <td>103.250298</td>\n",
       "      <td>-46.157928</td>\n",
       "      <td>55.580742</td>\n",
       "      <td>-14.027334</td>\n",
       "      <td>6.038419</td>\n",
       "      <td>-17.537346</td>\n",
       "      <td>-1.607846</td>\n",
       "      <td>10.737667</td>\n",
       "      <td>-4.196127</td>\n",
       "      <td>...</td>\n",
       "      <td>3.346047</td>\n",
       "      <td>2.461340</td>\n",
       "      <td>2.484034</td>\n",
       "      <td>3.027887</td>\n",
       "      <td>4.524765</td>\n",
       "      <td>2.431338</td>\n",
       "      <td>2.143259</td>\n",
       "      <td>-1.152794</td>\n",
       "      <td>-0.398699</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-350.193420</td>\n",
       "      <td>107.248901</td>\n",
       "      <td>-42.734859</td>\n",
       "      <td>57.279823</td>\n",
       "      <td>-20.294600</td>\n",
       "      <td>7.000971</td>\n",
       "      <td>-20.205288</td>\n",
       "      <td>0.712615</td>\n",
       "      <td>8.332971</td>\n",
       "      <td>-5.744866</td>\n",
       "      <td>...</td>\n",
       "      <td>4.356198</td>\n",
       "      <td>5.268185</td>\n",
       "      <td>3.117359</td>\n",
       "      <td>2.990666</td>\n",
       "      <td>4.309646</td>\n",
       "      <td>1.087925</td>\n",
       "      <td>3.075779</td>\n",
       "      <td>-1.321528</td>\n",
       "      <td>-0.485248</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-332.210236</td>\n",
       "      <td>85.976257</td>\n",
       "      <td>-48.348248</td>\n",
       "      <td>69.380257</td>\n",
       "      <td>-40.846989</td>\n",
       "      <td>16.268087</td>\n",
       "      <td>-18.902851</td>\n",
       "      <td>4.667327</td>\n",
       "      <td>-1.255777</td>\n",
       "      <td>-9.278911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714280</td>\n",
       "      <td>3.771701</td>\n",
       "      <td>3.293021</td>\n",
       "      <td>6.363577</td>\n",
       "      <td>5.758886</td>\n",
       "      <td>5.278218</td>\n",
       "      <td>5.895327</td>\n",
       "      <td>2.725751</td>\n",
       "      <td>5.918876</td>\n",
       "      <td>1183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-357.773712</td>\n",
       "      <td>71.274269</td>\n",
       "      <td>-42.503311</td>\n",
       "      <td>60.584373</td>\n",
       "      <td>-35.303238</td>\n",
       "      <td>17.293619</td>\n",
       "      <td>-15.609378</td>\n",
       "      <td>6.867744</td>\n",
       "      <td>1.937046</td>\n",
       "      <td>-5.049085</td>\n",
       "      <td>...</td>\n",
       "      <td>1.855946</td>\n",
       "      <td>4.151828</td>\n",
       "      <td>2.450951</td>\n",
       "      <td>4.508115</td>\n",
       "      <td>3.960655</td>\n",
       "      <td>2.327166</td>\n",
       "      <td>2.475070</td>\n",
       "      <td>1.046758</td>\n",
       "      <td>2.496841</td>\n",
       "      <td>1183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-303.967895</td>\n",
       "      <td>64.737312</td>\n",
       "      <td>-54.952255</td>\n",
       "      <td>74.819206</td>\n",
       "      <td>-51.354740</td>\n",
       "      <td>35.492699</td>\n",
       "      <td>-36.256485</td>\n",
       "      <td>17.553371</td>\n",
       "      <td>-2.504867</td>\n",
       "      <td>-4.041581</td>\n",
       "      <td>...</td>\n",
       "      <td>2.237770</td>\n",
       "      <td>7.552730</td>\n",
       "      <td>2.001996</td>\n",
       "      <td>5.793243</td>\n",
       "      <td>4.450655</td>\n",
       "      <td>4.712308</td>\n",
       "      <td>2.914915</td>\n",
       "      <td>1.277921</td>\n",
       "      <td>2.879731</td>\n",
       "      <td>1183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-300.962677</td>\n",
       "      <td>79.510307</td>\n",
       "      <td>-63.190033</td>\n",
       "      <td>59.666374</td>\n",
       "      <td>-51.259167</td>\n",
       "      <td>22.471220</td>\n",
       "      <td>-22.510559</td>\n",
       "      <td>6.808994</td>\n",
       "      <td>1.763889</td>\n",
       "      <td>-3.140162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.221693</td>\n",
       "      <td>5.219234</td>\n",
       "      <td>1.889757</td>\n",
       "      <td>4.121166</td>\n",
       "      <td>5.279699</td>\n",
       "      <td>4.933600</td>\n",
       "      <td>5.336883</td>\n",
       "      <td>2.102623</td>\n",
       "      <td>3.682725</td>\n",
       "      <td>1183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-335.889191</td>\n",
       "      <td>72.264420</td>\n",
       "      <td>-40.293816</td>\n",
       "      <td>59.391968</td>\n",
       "      <td>-40.045418</td>\n",
       "      <td>22.150768</td>\n",
       "      <td>-19.524826</td>\n",
       "      <td>7.467863</td>\n",
       "      <td>1.185511</td>\n",
       "      <td>-6.154644</td>\n",
       "      <td>...</td>\n",
       "      <td>1.595027</td>\n",
       "      <td>3.347951</td>\n",
       "      <td>2.166444</td>\n",
       "      <td>4.910305</td>\n",
       "      <td>4.709242</td>\n",
       "      <td>4.256351</td>\n",
       "      <td>4.368274</td>\n",
       "      <td>0.660498</td>\n",
       "      <td>2.739550</td>\n",
       "      <td>1183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1          2          3          4          5  \\\n",
       "0   -379.455688   97.028137 -36.862133  58.326141 -14.381740  18.083685   \n",
       "1   -350.678436  104.953583 -50.797516  63.575645 -20.301023  16.125052   \n",
       "2   -338.924103  103.865723 -51.616165  55.547260 -14.175528  12.698159   \n",
       "3   -346.993133  103.250298 -46.157928  55.580742 -14.027334   6.038419   \n",
       "4   -350.193420  107.248901 -42.734859  57.279823 -20.294600   7.000971   \n",
       "..          ...         ...        ...        ...        ...        ...   \n",
       "995 -332.210236   85.976257 -48.348248  69.380257 -40.846989  16.268087   \n",
       "996 -357.773712   71.274269 -42.503311  60.584373 -35.303238  17.293619   \n",
       "997 -303.967895   64.737312 -54.952255  74.819206 -51.354740  35.492699   \n",
       "998 -300.962677   79.510307 -63.190033  59.666374 -51.259167  22.471220   \n",
       "999 -335.889191   72.264420 -40.293816  59.391968 -40.045418  22.150768   \n",
       "\n",
       "             6          7          8         9  ...        31        32  \\\n",
       "0   -13.535484  -1.980425   6.867363 -1.436182  ...  6.590969  4.147519   \n",
       "1   -18.338022  -4.701718   5.564232 -3.718176  ...  5.044738  4.084303   \n",
       "2   -15.529408  -6.788486   6.311726 -1.932351  ...  5.090059  3.858420   \n",
       "3   -17.537346  -1.607846  10.737667 -4.196127  ...  3.346047  2.461340   \n",
       "4   -20.205288   0.712615   8.332971 -5.744866  ...  4.356198  5.268185   \n",
       "..         ...        ...        ...       ...  ...       ...       ...   \n",
       "995 -18.902851   4.667327  -1.255777 -9.278911  ...  0.714280  3.771701   \n",
       "996 -15.609378   6.867744   1.937046 -5.049085  ...  1.855946  4.151828   \n",
       "997 -36.256485  17.553371  -2.504867 -4.041581  ...  2.237770  7.552730   \n",
       "998 -22.510559   6.808994   1.763889 -3.140162  ...  3.221693  5.219234   \n",
       "999 -19.524826   7.467863   1.185511 -6.154644  ...  1.595027  3.347951   \n",
       "\n",
       "           33        34        35        36        37        38        39  \\\n",
       "0    2.915069  2.506089  2.704373  0.896116  0.402769 -2.776433 -0.392300   \n",
       "1    2.290769  1.581125  2.657886  1.554843  2.869262 -0.345722  1.761455   \n",
       "2    1.970551  1.166767  4.533372  2.390000  2.891569 -0.540090 -0.186476   \n",
       "3    2.484034  3.027887  4.524765  2.431338  2.143259 -1.152794 -0.398699   \n",
       "4    3.117359  2.990666  4.309646  1.087925  3.075779 -1.321528 -0.485248   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  3.293021  6.363577  5.758886  5.278218  5.895327  2.725751  5.918876   \n",
       "996  2.450951  4.508115  3.960655  2.327166  2.475070  1.046758  2.496841   \n",
       "997  2.001996  5.793243  4.450655  4.712308  2.914915  1.277921  2.879731   \n",
       "998  1.889757  4.121166  5.279699  4.933600  5.336883  2.102623  3.682725   \n",
       "999  2.166444  4.910305  4.709242  4.256351  4.368274  0.660498  2.739550   \n",
       "\n",
       "     Speaker_ID  \n",
       "0           103  \n",
       "1           103  \n",
       "2           103  \n",
       "3           103  \n",
       "4           103  \n",
       "..          ...  \n",
       "995        1183  \n",
       "996        1183  \n",
       "997        1183  \n",
       "998        1183  \n",
       "999        1183  \n",
       "\n",
       "[1000 rows x 41 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=data[0:1000]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9d63faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = z.iloc[:, 0:-1]\n",
    "b = z.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8624e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 40), (1000,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1fee7cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(a)\n",
    "b = np.array(b)\n",
    "a = a[:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e255a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 40, 1), (1000,))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c55d7168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28538,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4090f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,shuffle=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "458ec9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1,x_test1,y_train1,y_test1=train_test_split(x,y,test_size=0.2,shuffle=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52b07747",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1 = np.array(y_train1)\n",
    "y_test1 = np.array(y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "073bb00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22830,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cd965b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cfd3754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22830, 40), (22830,), (5708, 40), (5708,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d119e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22830, 40, 1), (22830, 251), (5708, 40, 1), (5708, 251))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train[:,:,np.newaxis]\n",
    "x_test = x_test[:,:,np.newaxis]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "le = LabelEncoder()\n",
    "y_train = to_categorical(le.fit_transform(y_train)) \n",
    "y_test = to_categorical(le.fit_transform(y_test)) \n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50f30f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca6de901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 40, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 40, 32)            256       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 40, 32)            128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 20, 64)            18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 20, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 10, 128)           57472     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 5, 256)            198144    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 251)               64507     \n",
      "=================================================================\n",
      "Total params: 405,563\n",
      "Trainable params: 405,115\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from keras.layers import Layer, Input\n",
    "from keras import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout,Conv1D,Activation,GRU,Bidirectional,BatchNormalization,Attention\n",
    "from tensorflow.keras.layers import MaxPooling1D,GlobalAveragePooling1D, GlobalMaxPooling1D,concatenate\n",
    "from keras.layers import Layer, Input, Conv1D, Bidirectional, LSTM, Dense, Dropout, BatchNormalization, GlobalMaxPooling1D, Flatten\n",
    "import tensorflow as tf \n",
    "\n",
    "sequence_input= Input(shape=(40,1), dtype='float32')\n",
    "a=Conv1D(filters=32, kernel_size=7, padding='same', activation='relu')(sequence_input)\n",
    "a=BatchNormalization()(a)\n",
    "a=MaxPooling1D(pool_size=2)(a)\n",
    "#x=Dropout(0.3)(x)\n",
    "c=Conv1D(filters=64, kernel_size=9, padding='same', activation='relu')(a)\n",
    "c=BatchNormalization()(c)\n",
    "c=MaxPooling1D(pool_size=2)(c)\n",
    "c=Conv1D(filters=128, kernel_size=7, padding='same', activation='relu')(c)\n",
    "c=BatchNormalization()(c)\n",
    "c=MaxPooling1D(pool_size=2)(c)\n",
    "#c=Conv1D(filters=128, kernel_size=5, padding='same', activation='relu')(c)\n",
    "#c=BatchNormalization()(c)\n",
    "#c=GlobalAveragePooling1D()(c)\n",
    "#c=Dropout(0.3)(c)\n",
    "d=Bidirectional(GRU(units=128,return_sequences=True))(c)\n",
    "#d=Dropout(0.2)(d)\n",
    "#d=Bidirectional(GRU(units=64,return_sequences=True))(d)\n",
    "\n",
    "d=GlobalAveragePooling1D()(d)\n",
    "e = Dense(256, activation='relu')(d)\n",
    "outp=Dense(units=251, activation='softmax')(e)\n",
    "model= Model(sequence_input,outp) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c17a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a438d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CET_Pc\\Anaconda3\\envs\\tensor\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "learning_rate = 0.0001\n",
    "optimizer=keras.optimizers.Adam(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6bc2574e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "714/714 [==============================] - 14s 14ms/step - loss: 3.8270 - accuracy: 0.2940 - val_loss: 2.1509 - val_accuracy: 0.6421\n",
      "Epoch 2/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 1.3379 - accuracy: 0.7955 - val_loss: 0.7855 - val_accuracy: 0.8858\n",
      "Epoch 3/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.5753 - accuracy: 0.9165 - val_loss: 0.3926 - val_accuracy: 0.9404\n",
      "Epoch 4/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.3086 - accuracy: 0.9580 - val_loss: 0.2225 - val_accuracy: 0.9702\n",
      "Epoch 5/100\n",
      "714/714 [==============================] - 10s 13ms/step - loss: 0.1951 - accuracy: 0.9730 - val_loss: 0.1676 - val_accuracy: 0.9755\n",
      "Epoch 6/100\n",
      "714/714 [==============================] - 10s 13ms/step - loss: 0.1317 - accuracy: 0.9818 - val_loss: 0.1377 - val_accuracy: 0.9769\n",
      "Epoch 7/100\n",
      "714/714 [==============================] - 10s 13ms/step - loss: 0.0935 - accuracy: 0.9877 - val_loss: 0.0989 - val_accuracy: 0.9828\n",
      "Epoch 8/100\n",
      "714/714 [==============================] - 10s 14ms/step - loss: 0.0699 - accuracy: 0.9904 - val_loss: 0.0764 - val_accuracy: 0.9842\n",
      "Epoch 9/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0522 - accuracy: 0.9939 - val_loss: 0.0714 - val_accuracy: 0.9869\n",
      "Epoch 10/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0444 - accuracy: 0.9934 - val_loss: 0.0872 - val_accuracy: 0.9818\n",
      "Epoch 11/100\n",
      "714/714 [==============================] - 10s 13ms/step - loss: 0.0323 - accuracy: 0.9966 - val_loss: 0.0530 - val_accuracy: 0.9891\n",
      "Epoch 12/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0250 - accuracy: 0.9974 - val_loss: 0.0495 - val_accuracy: 0.9888\n",
      "Epoch 13/100\n",
      "714/714 [==============================] - 10s 14ms/step - loss: 0.0207 - accuracy: 0.9980 - val_loss: 0.0641 - val_accuracy: 0.9851\n",
      "Epoch 14/100\n",
      "714/714 [==============================] - 10s 14ms/step - loss: 0.0172 - accuracy: 0.9985 - val_loss: 0.0722 - val_accuracy: 0.9844\n",
      "Epoch 15/100\n",
      "714/714 [==============================] - 10s 14ms/step - loss: 0.0180 - accuracy: 0.9975 - val_loss: 0.0458 - val_accuracy: 0.9883\n",
      "Epoch 16/100\n",
      "714/714 [==============================] - 10s 14ms/step - loss: 0.0101 - accuracy: 0.9994 - val_loss: 0.0592 - val_accuracy: 0.9844\n",
      "Epoch 17/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0114 - accuracy: 0.9988 - val_loss: 0.0419 - val_accuracy: 0.9900\n",
      "Epoch 18/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0112 - accuracy: 0.9986 - val_loss: 0.0419 - val_accuracy: 0.9898\n",
      "Epoch 19/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0089 - accuracy: 0.9991 - val_loss: 0.0594 - val_accuracy: 0.9856\n",
      "Epoch 20/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0086 - accuracy: 0.9988 - val_loss: 0.0471 - val_accuracy: 0.9884\n",
      "Epoch 21/100\n",
      "714/714 [==============================] - 9s 12ms/step - loss: 0.0050 - accuracy: 0.9996 - val_loss: 0.0552 - val_accuracy: 0.9849\n",
      "Epoch 22/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 0.0339 - val_accuracy: 0.9921\n",
      "Epoch 23/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9909\n",
      "Epoch 24/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0154 - accuracy: 0.9963 - val_loss: 0.0397 - val_accuracy: 0.9902\n",
      "Epoch 25/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9897\n",
      "Epoch 26/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.0524 - val_accuracy: 0.9879\n",
      "Epoch 27/100\n",
      "714/714 [==============================] - 10s 14ms/step - loss: 0.0079 - accuracy: 0.9988 - val_loss: 0.0389 - val_accuracy: 0.9905\n",
      "Epoch 28/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0351 - val_accuracy: 0.9897\n",
      "Epoch 29/100\n",
      "714/714 [==============================] - 10s 15ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0322 - val_accuracy: 0.9912\n",
      "Epoch 30/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0402 - val_accuracy: 0.9900\n",
      "Epoch 31/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0556 - val_accuracy: 0.9876\n",
      "Epoch 32/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0279 - val_accuracy: 0.9930\n",
      "Epoch 33/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.0475 - val_accuracy: 0.9874\n",
      "Epoch 34/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9923\n",
      "Epoch 35/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0403 - val_accuracy: 0.9897\n",
      "Epoch 36/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.0898 - val_accuracy: 0.9770\n",
      "Epoch 37/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0325 - val_accuracy: 0.9918\n",
      "Epoch 38/100\n",
      "714/714 [==============================] - 9s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9942\n",
      "Epoch 39/100\n",
      "714/714 [==============================] - 9s 12ms/step - loss: 6.7068e-04 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9939\n",
      "Epoch 40/100\n",
      "714/714 [==============================] - 8s 12ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.0467 - val_accuracy: 0.9881\n",
      "Epoch 41/100\n",
      "714/714 [==============================] - 9s 12ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0285 - val_accuracy: 0.9933\n",
      "Epoch 42/100\n",
      "714/714 [==============================] - 9s 12ms/step - loss: 9.7179e-04 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9937\n",
      "Epoch 43/100\n",
      "714/714 [==============================] - 9s 12ms/step - loss: 4.3453e-04 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9940\n",
      "Epoch 44/100\n",
      "714/714 [==============================] - 9s 12ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.0373 - val_accuracy: 0.9911\n",
      "Epoch 45/100\n",
      "714/714 [==============================] - 9s 12ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0315 - val_accuracy: 0.9925\n",
      "Epoch 46/100\n",
      "714/714 [==============================] - 9s 12ms/step - loss: 8.9704e-04 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9944\n",
      "Epoch 47/100\n",
      "714/714 [==============================] - 9s 12ms/step - loss: 3.2237e-04 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9944\n",
      "Epoch 48/100\n",
      "714/714 [==============================] - 9s 12ms/step - loss: 2.6040e-04 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9940\n",
      "Epoch 49/100\n",
      "714/714 [==============================] - 9s 12ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.0375 - val_accuracy: 0.9905\n",
      "Epoch 50/100\n",
      "714/714 [==============================] - 9s 12ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0263 - val_accuracy: 0.9939\n",
      "Epoch 51/100\n",
      "714/714 [==============================] - 10s 14ms/step - loss: 7.3270e-04 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 0.9918\n",
      "Epoch 52/100\n",
      "714/714 [==============================] - 10s 13ms/step - loss: 6.9153e-04 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9939\n",
      "Epoch 53/100\n",
      "714/714 [==============================] - 10s 14ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0437 - val_accuracy: 0.9890\n",
      "Epoch 54/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0278 - val_accuracy: 0.9932\n",
      "Epoch 55/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 2.9964e-04 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9932\n",
      "Epoch 56/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 2.4328e-04 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9937\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 0.0281 - val_accuracy: 0.9930\n",
      "Epoch 58/100\n",
      "714/714 [==============================] - 9s 13ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0264 - val_accuracy: 0.9932\n",
      "Epoch 00058: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,batch_size=32,epochs=epochs,verbose=1,shuffle=True,validation_data=(x_test, y_test),callbacks=[es])        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94a278f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.026371123269200325\n",
      "Test accuracy: 0.9931674599647522\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "32f4cc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CET_Pc\\Anaconda3\\envs\\tensor\\lib\\site-packages\\seaborn\\axisgrid.py:337: UserWarning: The `size` parameter has been renamed to `height`; please update your code.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 287x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sn\n",
    "tsne_data = model.predict(a)\n",
    "tsne_data = TSNE(n_components=2, perplexity=150).fit_transform(tsne_data)\n",
    "import matplotlib.pyplot as pltt\n",
    "\n",
    "#tsne_data = model1.fit_transform(x_train1) \n",
    "\n",
    "# creating a new data fram which help us in ploting the result data\n",
    "tsne_data = np.vstack((tsne_data.T, b)).T\n",
    "tsne_df = pd.DataFrame(tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"speaker_ID\"))\n",
    "\n",
    "# Ploting the result of tsne\n",
    "sn.FacetGrid(tsne_df, hue=\"speaker_ID\", size=3).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\n",
    "#plt.title('With perplexity = 200')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687bee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
